{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Persiapan Environment**"
      ],
      "metadata": {
        "id": "rv3v3gklmGyt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8w_89h8cvfD",
        "outputId": "d9cf681e-d816-4a37-dbf1-6ca82646e487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Ekstraksi Data**"
      ],
      "metadata": {
        "id": "-MiGkhDnmNHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the archive\n",
        "local_zip = '/content/drive/MyDrive/Data Product 75.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "tAUTdA50c4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Pemisahan Dataset**"
      ],
      "metadata": {
        "id": "zD4CRE7QmSlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Path to the folder containing the images\n",
        "folder_path = \"/content/tmp/Data Product\"\n",
        "\n",
        "train_path = \"/content/tmp/train_folder/\"\n",
        "val_path = \"/content/tmp/val_folder/\"\n",
        "test_path = \"/content/tmp/test_folder/\"\n",
        "\n",
        "# List of classes (subdirectories)\n",
        "classes = os.listdir(folder_path)\n",
        "\n",
        "# Create directories for train, val, and test sets\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_path, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_path, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, class_name), exist_ok=True)\n",
        "\n",
        "# Split the data into train, val, and test sets\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(folder_path, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    train_size = int(0.70 * len(images))\n",
        "    val_size = int(0.20 * len(images))\n",
        "\n",
        "    train_images = images[:train_size]\n",
        "    val_images = images[train_size:train_size + val_size]\n",
        "    test_images = images[train_size + val_size:]\n",
        "\n",
        "    # Copy images to train set\n",
        "    for image in train_images:\n",
        "        src = os.path.join(class_path, image)\n",
        "        dst = os.path.join(train_path, class_name, image)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    # Copy images to val set\n",
        "    for image in val_images:\n",
        "        src = os.path.join(class_path, image)\n",
        "        dst = os.path.join(val_path, class_name, image)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    # Copy images to test set\n",
        "    for image in test_images:\n",
        "        src = os.path.join(class_path, image)\n",
        "        dst = os.path.join(test_path, class_name, image)\n",
        "        shutil.copy(src, dst)"
      ],
      "metadata": {
        "id": "jCxQYERRdOmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Augmentasi Data dan Persiapan Generator**"
      ],
      "metadata": {
        "id": "iY5jWA5jmU04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Ukuran gambar untuk model\n",
        "img_width, img_height = 150, 150\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Normalize pixel [0, 1]\n",
        "    rotation_range=20,       # rotate gambar\n",
        "    width_shift_range=0.2,   # shift horizontally\n",
        "    height_shift_range=0.2,  # shift vertically\n",
        "    horizontal_flip=True,    # flip horizontally\n",
        "    shear_range=0.2,         # shear gambar\n",
        "    zoom_range=0.2,           # zoom gambar\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "# rescale untuk validation/test\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGmjuLl3dRXD",
        "outputId": "f9c4eaa8-e32a-4919-94df-7efb4a3d4af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2660 images belonging to 76 classes.\n",
            "Found 760 images belonging to 76 classes.\n",
            "Found 380 images belonging to 76 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Pembuatan Model**"
      ],
      "metadata": {
        "id": "d6hw7uNOmoGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(classes), activation='softmax'))"
      ],
      "metadata": {
        "id": "JujU30Jkd5UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEXVquUU5uz9",
        "outputId": "9f7a8f5e-0bde-4e1f-e1f4-97621ab3d5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               4735104   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 76)                9804      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4838156 (18.46 MB)\n",
            "Trainable params: 4838156 (18.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Pelatihan Model**"
      ],
      "metadata": {
        "id": "sl8BEbPFmrXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpHrxKEpd7TS",
        "outputId": "ff942375-afe1-45cc-d44a-3eef1d09050f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "83/83 [==============================] - 57s 612ms/step - loss: 4.3322 - accuracy: 0.0213 - val_loss: 4.2313 - val_accuracy: 0.0204\n",
            "Epoch 2/25\n",
            "83/83 [==============================] - 52s 633ms/step - loss: 3.9322 - accuracy: 0.0772 - val_loss: 2.9334 - val_accuracy: 0.2459\n",
            "Epoch 3/25\n",
            "83/83 [==============================] - 50s 603ms/step - loss: 3.1702 - accuracy: 0.1838 - val_loss: 1.6478 - val_accuracy: 0.5965\n",
            "Epoch 4/25\n",
            "83/83 [==============================] - 47s 568ms/step - loss: 2.4280 - accuracy: 0.3128 - val_loss: 0.9862 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "83/83 [==============================] - 49s 592ms/step - loss: 1.9389 - accuracy: 0.4209 - val_loss: 0.5465 - val_accuracy: 0.8546\n",
            "Epoch 6/25\n",
            "83/83 [==============================] - 51s 617ms/step - loss: 1.5744 - accuracy: 0.5175 - val_loss: 0.3365 - val_accuracy: 0.9212\n",
            "Epoch 7/25\n",
            "83/83 [==============================] - 50s 601ms/step - loss: 1.3285 - accuracy: 0.5875 - val_loss: 0.2738 - val_accuracy: 0.9226\n",
            "Epoch 8/25\n",
            "83/83 [==============================] - 50s 598ms/step - loss: 1.1653 - accuracy: 0.6298 - val_loss: 0.2323 - val_accuracy: 0.9389\n",
            "Epoch 9/25\n",
            "83/83 [==============================] - 46s 558ms/step - loss: 1.0243 - accuracy: 0.6758 - val_loss: 0.1997 - val_accuracy: 0.9321\n",
            "Epoch 10/25\n",
            "83/83 [==============================] - 50s 608ms/step - loss: 0.9340 - accuracy: 0.6910 - val_loss: 0.1695 - val_accuracy: 0.9416\n",
            "Epoch 11/25\n",
            "83/83 [==============================] - 50s 608ms/step - loss: 0.8433 - accuracy: 0.7264 - val_loss: 0.1094 - val_accuracy: 0.9647\n",
            "Epoch 12/25\n",
            "83/83 [==============================] - 47s 567ms/step - loss: 0.7926 - accuracy: 0.7409 - val_loss: 0.0873 - val_accuracy: 0.9837\n",
            "Epoch 13/25\n",
            "83/83 [==============================] - 50s 604ms/step - loss: 0.7925 - accuracy: 0.7477 - val_loss: 0.1043 - val_accuracy: 0.9783\n",
            "Epoch 14/25\n",
            "83/83 [==============================] - 49s 584ms/step - loss: 0.6824 - accuracy: 0.7702 - val_loss: 0.1195 - val_accuracy: 0.9484\n",
            "Epoch 15/25\n",
            "83/83 [==============================] - 45s 543ms/step - loss: 0.6398 - accuracy: 0.7907 - val_loss: 0.0561 - val_accuracy: 0.9905\n",
            "Epoch 16/25\n",
            "83/83 [==============================] - 49s 594ms/step - loss: 0.5891 - accuracy: 0.8113 - val_loss: 0.0499 - val_accuracy: 0.9891\n",
            "Epoch 17/25\n",
            "83/83 [==============================] - 50s 604ms/step - loss: 0.5748 - accuracy: 0.8132 - val_loss: 0.0687 - val_accuracy: 0.9823\n",
            "Epoch 18/25\n",
            "83/83 [==============================] - 50s 601ms/step - loss: 0.5214 - accuracy: 0.8261 - val_loss: 0.0797 - val_accuracy: 0.9769\n",
            "Epoch 19/25\n",
            "83/83 [==============================] - 50s 601ms/step - loss: 0.5330 - accuracy: 0.8246 - val_loss: 0.0632 - val_accuracy: 0.9715\n",
            "Epoch 20/25\n",
            "83/83 [==============================] - 49s 589ms/step - loss: 0.5227 - accuracy: 0.8307 - val_loss: 0.0568 - val_accuracy: 0.9823\n",
            "Epoch 21/25\n",
            "83/83 [==============================] - 46s 546ms/step - loss: 0.5528 - accuracy: 0.8124 - val_loss: 0.0349 - val_accuracy: 0.9918\n",
            "Epoch 22/25\n",
            "83/83 [==============================] - 52s 623ms/step - loss: 0.5117 - accuracy: 0.8303 - val_loss: 0.0524 - val_accuracy: 0.9810\n",
            "Epoch 23/25\n",
            "83/83 [==============================] - 45s 544ms/step - loss: 0.4049 - accuracy: 0.8718 - val_loss: 0.0219 - val_accuracy: 0.9905\n",
            "Epoch 24/25\n",
            "83/83 [==============================] - 48s 586ms/step - loss: 0.4412 - accuracy: 0.8512 - val_loss: 0.0175 - val_accuracy: 0.9986\n",
            "Epoch 25/25\n",
            "83/83 [==============================] - 45s 548ms/step - loss: 0.4564 - accuracy: 0.8451 - val_loss: 0.0289 - val_accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f097bf9fe20>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Evaluasi dan Penyimpanan Model**"
      ],
      "metadata": {
        "id": "OKtSTm_lmtfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt-NDYYipGCH",
        "outputId": "37d52288-9026-492d-f51c-d1d38d83dc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 4s 294ms/step - loss: 0.0233 - accuracy: 0.9974\n",
            "Test Loss: 0.023268526419997215\n",
            "Test Accuracy: 0.9973683953285217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/model klasifikasi minuman/model_v1.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdsJj0aItYrF",
        "outputId": "4a9dac0a-7ca5-448d-f19a-71321efc1726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class_indices = train_generator.class_indices  # Ambil pemetaan kelas\n",
        "class_indices_json = json.dumps(class_indices, indent=4)  # Ubah ke JSON dengan indentasi\n",
        "\n",
        "# Simpan ke file\n",
        "with open(\"class_indices.json\", \"w\") as f:\n",
        "    f.write(class_indices_json)"
      ],
      "metadata": {
        "id": "JPME85z5mfak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Prediksi**\n"
      ],
      "metadata": {
        "id": "vENVbFYsmzlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = validation_generator.class_indices\n",
        "index_to_class = {v: k for k, v in class_indices.items()}"
      ],
      "metadata": {
        "id": "xbO2Xn-bpIJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from IPython.display import Image, display\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "    # Display the uploaded image\n",
        "    display(Image(fn))\n",
        "\n",
        "    # Prediction\n",
        "    path = fn\n",
        "    img = load_img(path, target_size=(150, 150))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = x / 255.0\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images)\n",
        "    predicted_class_index = np.argmax(classes, axis=1)[0]\n",
        "    predicted_class_label = index_to_class[predicted_class_index]\n",
        "    print(fn)\n",
        "    print(predicted_class_label)"
      ],
      "metadata": {
        "id": "am0GM--fpedh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}